{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Preprocessing</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before executing:\n",
    "# pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids =   {\n",
    "                \"parkinsons\": 174,\n",
    "                \"page-blocks\": 78,\n",
    "                \"optical\": 80,\n",
    "                \"musk2\": 75,\n",
    "                \"bc-wisc-diag\": 17,\n",
    "                \"students\": 697,\n",
    "                \"wine\": 109,\n",
    "                \"magic\": 159,\n",
    "                \"balance-scale\": 12,\n",
    "                \"glass\": 42,\n",
    "                \"zoo\": 111,\n",
    "                \"waveform\": 107,\n",
    "                \"image-segmentation\": 50,\n",
    "                \"blood\": 176,\n",
    "                \"spect\": 95,\n",
    "                \"yeast\": 110,\n",
    "                \"monk\": 70,\n",
    "                \"ecoli\": 39,\n",
    "                \"iris\": 53,\n",
    "                \"contraception\": 30,\n",
    "                \"fertility\": 244,\n",
    "                \"conn-bench-sonar\":  151,\n",
    "                \"landsat\": 146,\n",
    "                \"ionosphere\": 52,\n",
    "                \"letter\": 59,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(id):  \n",
    "    # fetch dataset \n",
    "    dataset = fetch_ucirepo(id=id) \n",
    "    \n",
    "    # data (as pandas dataframes) \n",
    "    X = dataset.data.features \n",
    "    y =dataset.data.targets \n",
    "    \n",
    "    # dictionary gthering infos about the metadata (url, abstract, ... etc.)\n",
    "    metadata_infos_dict = dataset.metadata\n",
    "    print('data url:\\n', metadata_infos_dict['data_url'])\n",
    "    \n",
    "    # variable information\n",
    "    var_infos = dataset.variables.to_numpy()\n",
    "    \n",
    "    data_vectors = X.to_numpy() #instance vectors with features\n",
    "    features_names = X.columns.to_numpy() #getting the names of each feature\n",
    "    \n",
    "    data_labels = y.to_numpy() #output labels for each instance\n",
    "    label_name = y.columns.to_numpy() # name of the output label\n",
    "    \n",
    "    return data_vectors, features_names, data_labels, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_useful_data(X, X_names, y, y_name, index = 0):\n",
    "    n_instances = len(X)\n",
    "    n_features = len(X_names)\n",
    "    \n",
    "    print(\"number of instances: \", n_instances)\n",
    "    print(\"number of features: \", n_features)\n",
    "\n",
    "    print(\"names of the features:\\n\", X_names)\n",
    "    print(\"name of the output label: \", y_name)\n",
    "\n",
    "    print(f\"instance {index} feature vector:\\n\", X[index])\n",
    "    print(f\"instance {index} output label: \", y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y, split=0.7):\n",
    "    scaler = StandardScaler()\n",
    "    try:\n",
    "        #standardization\n",
    "        X = scaler.fit_transform(X)\n",
    "    except ValueError:\n",
    "        #If non numerical data is detected, data is encoded\n",
    "        X = np.array(X, dtype=object)\n",
    "        encoder = OneHotEncoder()\n",
    "        X_encoded = encoder.fit_transform(X).toarray()\n",
    "        X = scaler.fit_transform(X_encoded)\n",
    "    \n",
    "    #data is split among training and testing sets\n",
    "    return train_test_split(X, y, train_size=split, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Gaussian Naive Bayes</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBayes:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.mean = {}\n",
    "        self.variance = {}\n",
    "        self.prior = {}\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.classes = np.unique(Y_train)\n",
    "        \n",
    "        for singular_class in self.classes:\n",
    "            X_c = X_train[Y_train.flatten() == singular_class]\n",
    "            self.mean[singular_class] = np.mean(X_c, axis=0) \n",
    "            self.variance[singular_class] = np.var(X_c, axis=0)\n",
    "            self.prior[singular_class] = X_c.shape[0] / X_train.shape[0]\n",
    "            \n",
    "    def gaussian_density(self, x, mean, var, epsilon=1e-9):\n",
    "        # Stabilize variance to avoid division by zero\n",
    "        var = var + epsilon\n",
    "        return (1 / np.sqrt(2*np.pi*var)) * np.exp(-((x-mean)**2) / (2*var))\n",
    "    \n",
    "    def predict_sample(self, X):\n",
    "        probability = []\n",
    "        for singular_class in self.classes:\n",
    "            log_likelihood = np.sum(np.log(np.maximum(self.gaussian_density(X, self.mean[singular_class], self.variance[singular_class]), 1e-6)))\n",
    "            log_prior = np.log(self.prior[singular_class])\n",
    "            probability.append(log_prior + log_likelihood)\n",
    "        \n",
    "        probability = np.array(probability)\n",
    "        return self.classes[np.argmax(probability)]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.array([self.predict_sample(x) for x in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to visualize clusters using PCA\n",
    "def visualize_clusters(X, clusters, centroids, iteration, nb_cluster, cluster_labels=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']  #define colors for clusters\n",
    "\n",
    "    #reduce the data to 2D using PCA for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2D = pca.fit_transform(X) \n",
    "\n",
    "    #if cluster assignments are provided, color by cluster membership\n",
    "    if cluster_labels is not None:\n",
    "        for i in range(nb_cluster):\n",
    "            cluster_points_2D = X_2D[cluster_labels == i]\n",
    "            plt.scatter(cluster_points_2D[:, 0], cluster_points_2D[:, 1], \n",
    "                        color=colors[i % len(colors)], label=f'Cluster {i+1}')\n",
    "    else:\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            cluster_points = np.array(cluster)\n",
    "            cluster_points_2D = pca.transform(cluster_points)  #transform current cluster into 2D\n",
    "            plt.scatter(cluster_points_2D[:, 0], cluster_points_2D[:, 1], \n",
    "                        color=colors[i % len(colors)], label=f'Cluster {i+1}')\n",
    "\n",
    "    #plot centroids in 2D space\n",
    "    centroids_2D = pca.transform(centroids)  #transform centroids into 2D\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                color='black', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(f\"clusters and centroids - Iteration {iteration}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Accuracy, F1 and confusion matrice</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    \n",
    "    return accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Results on 25 datasets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Predict Students' Dropout and Academic Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/697/data.csv\n",
      "training set size: (3096, 36)\n",
      "testing set size: (1328, 36)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"students\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split=split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  4424\n",
      "number of features:  36\n",
      "names of the features:\n",
      " ['Marital Status' 'Application mode' 'Application order' 'Course'\n",
      " 'Daytime/evening attendance' 'Previous qualification'\n",
      " 'Previous qualification (grade)' 'Nacionality' \"Mother's qualification\"\n",
      " \"Father's qualification\" \"Mother's occupation\" \"Father's occupation\"\n",
      " 'Admission grade' 'Displaced' 'Educational special needs' 'Debtor'\n",
      " 'Tuition fees up to date' 'Gender' 'Scholarship holder'\n",
      " 'Age at enrollment' 'International' 'Curricular units 1st sem (credited)'\n",
      " 'Curricular units 1st sem (enrolled)'\n",
      " 'Curricular units 1st sem (evaluations)'\n",
      " 'Curricular units 1st sem (approved)' 'Curricular units 1st sem (grade)'\n",
      " 'Curricular units 1st sem (without evaluations)'\n",
      " 'Curricular units 2nd sem (credited)'\n",
      " 'Curricular units 2nd sem (enrolled)'\n",
      " 'Curricular units 2nd sem (evaluations)'\n",
      " 'Curricular units 2nd sem (approved)' 'Curricular units 2nd sem (grade)'\n",
      " 'Curricular units 2nd sem (without evaluations)' 'Unemployment rate'\n",
      " 'Inflation rate' 'GDP']\n",
      "name of the output label:  ['Target']\n",
      "instance 0 feature vector:\n",
      " [  1.    17.     5.   171.     1.     1.   122.     1.    19.    12.\n",
      "   5.     9.   127.3    1.     0.     0.     1.     1.     0.    20.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.    10.8    1.4    1.74]\n",
      "instance 0 output label:  ['Dropout']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 69.73%\n",
      "F1 score: 0.68\n",
      "confusion matrix:\n",
      "[[305  51  85]\n",
      " [ 39  61 145]\n",
      " [ 39  43 560]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/109/data.csv\n",
      "training set size: (124, 13)\n",
      "testing set size: (54, 13)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"wine\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  178\n",
      "number of features:  13\n",
      "names of the features:\n",
      " ['Alcohol' 'Malicacid' 'Ash' 'Alcalinity_of_ash' 'Magnesium'\n",
      " 'Total_phenols' 'Flavanoids' 'Nonflavanoid_phenols' 'Proanthocyanins'\n",
      " 'Color_intensity' 'Hue' '0D280_0D315_of_diluted_wines' 'Proline']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.15%\n",
      "F1 score: 0.98\n",
      "confusion matrix:\n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MAGIC gamma telescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/159/data.csv\n",
      "training set size: (13314, 10)\n",
      "testing set size: (5706, 10)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"magic\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  19020\n",
      "number of features:  10\n",
      "names of the features:\n",
      " ['fLength' 'fWidth' 'fSize' 'fConc' 'fConc1' 'fAsym' 'fM3Long' 'fM3Trans'\n",
      " 'fAlpha' 'fDist']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [28.7967 16.0021  2.6449  0.3918  0.1982 27.7004 22.011  -8.2027 40.092\n",
      " 81.8828]\n",
      "instance 0 output label:  ['g']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 72.75%\n",
      "F1 score: 0.70\n",
      "confusion matrix:\n",
      "[[3410  295]\n",
      " [1260  741]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/174/data.csv\n",
      "training set size: (136, 22)\n",
      "testing set size: (59, 22)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"parkinsons\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  195\n",
      "number of features:  22\n",
      "names of the features:\n",
      " ['MDVP:Fo' 'MDVP:Fhi' 'MDVP:Flo' 'MDVP:Jitter' 'MDVP:Jitter' 'MDVP:RAP'\n",
      " 'MDVP:PPQ' 'Jitter:DDP' 'MDVP:Shimmer' 'MDVP:Shimmer' 'Shimmer:APQ3'\n",
      " 'Shimmer:APQ5' 'MDVP:APQ' 'Shimmer:DDA' 'NHR' 'HNR' 'RPDE' 'DFA'\n",
      " 'spread1' 'spread2' 'D2' 'PPE']\n",
      "name of the output label:  ['status']\n",
      "instance 0 feature vector:\n",
      " [ 1.199920e+02  1.573020e+02  7.499700e+01  7.840000e-03  7.840000e-03\n",
      "  3.700000e-03  5.540000e-03  1.109000e-02  4.374000e-02  4.374000e-02\n",
      "  2.182000e-02  3.130000e-02  2.971000e-02  6.545000e-02  2.211000e-02\n",
      "  2.103300e+01  4.147830e-01  8.152850e-01 -4.813031e+00  2.664820e-01\n",
      "  2.301442e+00  2.846540e-01]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.27%\n",
      "F1 score: 0.78\n",
      "confusion matrix:\n",
      "[[12  3]\n",
      " [11 33]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Page-blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/78/data.csv\n",
      "training set size: (3831, 10)\n",
      "testing set size: (1642, 10)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"page-blocks\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  5473\n",
      "number of features:  10\n",
      "names of the features:\n",
      " ['height' 'length' 'area' 'eccen' 'p_black' 'p_and' 'mean_tr' 'blackpix'\n",
      " 'blackand' 'wb_trans']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [ 5.     7.    35.     1.4    0.4    0.657  2.33  14.    23.     6.   ]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.27%\n",
      "F1 score: 0.90\n",
      "confusion matrix:\n",
      "[[1311    7    8  118   22]\n",
      " [  24   79    1    2    0]\n",
      " [   2    0    7    0    1]\n",
      " [   0    2    0   28    1]\n",
      " [  12    0    5    4    8]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Optical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/80/data.csv\n",
      "training set size: (3933, 64)\n",
      "testing set size: (1687, 64)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"optical\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "\n",
    "num_sample = 6000\n",
    "X_train, X_test = X_train[:num_sample*2,:], X_test[:num_sample,:]\n",
    "Y_train, Y_test = Y_train[:num_sample*2], Y_test[:num_sample]\n",
    "\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  5620\n",
      "number of features:  64\n",
      "names of the features:\n",
      " ['Attribute1' 'Attribute2' 'Attribute3' 'Attribute4' 'Attribute5'\n",
      " 'Attribute6' 'Attribute7' 'Attribute8' 'Attribute9' 'Attribute10'\n",
      " 'Attribute11' 'Attribute12' 'Attribute13' 'Attribute14' 'Attribute15'\n",
      " 'Attribute16' 'Attribute17' 'Attribute18' 'Attribute19' 'Attribute20'\n",
      " 'Attribute21' 'Attribute22' 'Attribute23' 'Attribute24' 'Attribute25'\n",
      " 'Attribute26' 'Attribute27' 'Attribute28' 'Attribute29' 'Attribute30'\n",
      " 'Attribute31' 'Attribute32' 'Attribute33' 'Attribute34' 'Attribute35'\n",
      " 'Attribute36' 'Attribute37' 'Attribute38' 'Attribute39' 'Attribute40'\n",
      " 'Attribute41' 'Attribute42' 'Attribute43' 'Attribute44' 'Attribute45'\n",
      " 'Attribute46' 'Attribute47' 'Attribute48' 'Attribute49' 'Attribute50'\n",
      " 'Attribute51' 'Attribute52' 'Attribute53' 'Attribute54' 'Attribute55'\n",
      " 'Attribute56' 'Attribute57' 'Attribute58' 'Attribute59' 'Attribute60'\n",
      " 'Attribute61' 'Attribute62' 'Attribute63' 'Attribute64']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [ 0  1  6 15 12  1  0  0  0  7 16  6  6 10  0  0  0  8 16  2  0 11  2  0\n",
      "  0  5 16  3  0  5  7  0  0  7 13  3  0  8  7  0  0  4 12  0  1 13  5  0\n",
      "  0  0 14  9 15  9  0  0  0  0  6 14  7  1  0  0]\n",
      "instance 0 output label:  [0]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 61.94%\n",
      "F1 score: 0.60\n",
      "confusion matrix:\n",
      "[[170   0   0   0   0   0   0   0   0   0]\n",
      " [  0 116   0   0   0   0  14   0  38   5]\n",
      " [  2  12  66   0   0   0   0   0  74   0]\n",
      " [  7   0   0  50   0   0   0   8 104   4]\n",
      " [ 21  24   0   0  43   0  37  49   6   3]\n",
      " [ 21   1   0   0   0  46   1   8  74   2]\n",
      " [  1   1   0   0   0   0 166   0   0   0]\n",
      " [  0   3   0   0   0   0   0 180   3   0]\n",
      " [  3   2   0   0   0   0   0   1 147   0]\n",
      " [ 38   6   0   0   0   0   2  21  46  61]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/52/data.csv\n",
      "training set size: (245, 34)\n",
      "testing set size: (106, 34)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"ionosphere\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  351\n",
      "number of features:  34\n",
      "names of the features:\n",
      " ['Attribute1' 'Attribute2' 'Attribute3' 'Attribute4' 'Attribute5'\n",
      " 'Attribute6' 'Attribute7' 'Attribute8' 'Attribute9' 'Attribute10'\n",
      " 'Attribute11' 'Attribute12' 'Attribute13' 'Attribute14' 'Attribute15'\n",
      " 'Attribute16' 'Attribute17' 'Attribute18' 'Attribute19' 'Attribute20'\n",
      " 'Attribute21' 'Attribute22' 'Attribute23' 'Attribute24' 'Attribute25'\n",
      " 'Attribute26' 'Attribute27' 'Attribute28' 'Attribute29' 'Attribute30'\n",
      " 'Attribute31' 'Attribute32' 'Attribute33' 'Attribute34']\n",
      "name of the output label:  ['Class']\n",
      "instance 0 feature vector:\n",
      " [ 1.       0.       0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708\n",
      "  1.       0.0376   0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223\n",
      "  0.84356 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357\n",
      "  0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.3409   0.42267 -0.54487\n",
      "  0.18641 -0.453  ]\n",
      "instance 0 output label:  ['g']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.68%\n",
      "F1 score: 0.88\n",
      "confusion matrix:\n",
      "[[28 11]\n",
      " [ 1 66]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Glass Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/42/data.csv\n",
      "training set size: (149, 9)\n",
      "testing set size: (65, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"glass\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  214\n",
      "number of features:  9\n",
      "names of the features:\n",
      " ['RI' 'Na' 'Mg' 'Al' 'Si' 'K' 'Ca' 'Ba' 'Fe']\n",
      "name of the output label:  ['Type_of_glass']\n",
      "instance 0 feature vector:\n",
      " [1.52101e+00 1.36400e+01 4.49000e+00 1.10000e+00 7.17800e+01 6.00000e-02\n",
      " 8.75000e+00 0.00000e+00 0.00000e+00]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 21.54%\n",
      "F1 score: 0.21\n",
      "confusion matrix:\n",
      "[[ 0  1 18  0  0  0]\n",
      " [ 1  3 15  0  4  0]\n",
      " [ 1  0  3  0  0  0]\n",
      " [ 0  3  0  1  2  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  1  5  4]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Letter Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/59/data.csv\n",
      "training set size: (14000, 16)\n",
      "testing set size: (6000, 16)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"letter\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  20000\n",
      "number of features:  16\n",
      "names of the features:\n",
      " ['x-box' 'y-box' 'width' 'high' 'onpix' 'x-bar' 'y-bar' 'x2bar' 'y2bar'\n",
      " 'xybar' 'x2ybr' 'xy2br' 'x-ege' 'xegvy' 'y-ege' 'yegvx']\n",
      "name of the output label:  ['lettr']\n",
      "instance 0 feature vector:\n",
      " [ 2  8  3  5  1  8 13  0  6  6 10  8  0  8  0  8]\n",
      "instance 0 output label:  ['T']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 64.30%\n",
      "F1 score: 0.64\n",
      "confusion matrix:\n",
      "[[213   0   0   0   0   0   0   1   0   0   1   0   6   1   0   0   1   1\n",
      "    7   0   0   0   0   0   1   0]\n",
      " [  0 155   0   6   0   0   2   5  20   0   5   0   4   0   2   0   4  16\n",
      "    5   0   0   0   4   1   0   0]\n",
      " [  0   0 144   0   6   1  16   1   0   0  11   0   2   0   6   0   4   0\n",
      "    5   2   2   1   0   0   0   0]\n",
      " [  2  13   0 193   0   0   0   5   3   5   5   0   3   0   3   1   0  11\n",
      "    4   0   0   0   1   1   0   0]\n",
      " [  0   5   1   0  84   0  43   0  22   0   9   0   0   0   0   0  12   0\n",
      "   19   4   0   0   0  33   2   4]\n",
      " [  0   9   0   9   0 152   9   1   1   0   0   0   0   4   0   9   5   1\n",
      "    4   4   0   0   2   0   1   0]\n",
      " [  5   6  50   1   1   0 127   0   4   0   2   0   4   0   2   0  12   4\n",
      "    4   0   0   0   6   2   0   0]\n",
      " [  1   6   0  19   0   0   3  67   4   0   9   0   5   2  35   0   1  20\n",
      "    1   0   8   0   0  32   5   0]\n",
      " [  0   4   0  22   2   0   0   0 164   7   0   2   0   0   0   1   3   0\n",
      "   13   1   0   0   0   1   0   1]\n",
      " [  2   6   0  10   0   5   0   0   6 161   1   0   0   0   3   6   3   6\n",
      "   17   0   0   0   0   2   0   0]\n",
      " [  1   4   3   4  19   0   7   0   2   0  89   0   7   0   0   0   0  24\n",
      "    0   1   3   0   1  23   0   0]\n",
      " [  1   7   0   0   5   0   4   0   0  15   9 176   1   0   0   0   9   2\n",
      "    1   0   0   0   0   0   1   0]\n",
      " [  5   2   0   0   0   0   1   2   0   0   6   0 226   0   2   0   0   0\n",
      "    0   0   0   0   8   0   0   0]\n",
      " [  0   3   0   5   0   1   0  20   0   0   5   0   8 155   5   1   2   7\n",
      "    2   0   2   8   7   0   0   0]\n",
      " [  2   4   0   5   0   0   8   2  11   0   4   0   5   2 154   1   3  10\n",
      "    0   0   0   0   7   0   0   0]\n",
      " [  0   1   0   2   0  30  11   1   0   0   0   0   1   4   1 181   0   0\n",
      "    1   1   0   0  13   0   1   0]\n",
      " [  2   5   0   2   0   0   5   1   9   0   0   0   6   0  57   0 132   7\n",
      "   23   0   0   1   1   0   1   1]\n",
      " [  0  22   0  23   0   0   1   5   3   7   5   0  11   0   0   0   0 152\n",
      "    0   0   0   0   4   1   0   0]\n",
      " [ 15  33   0   3   5   2   2   2  19   0   2   0   1   0   0   1   4   3\n",
      "   84   7   1   0   0  29   0  22]\n",
      " [  0   1   1   1   1  13   4   0   0   0  13   0   1   0   0   0   0   1\n",
      "    2 160   1   2   0  10  18   3]\n",
      " [  0   0   4   1   0   2   3   9   0   0  11   0  22   6  14   0   1   0\n",
      "    0   0 184   0   4   0   0   0]\n",
      " [  0   3   0   0   0   2   2   3   0   0   1   0   2   0   0   4   0   1\n",
      "    0   0   0 194  18   0   7   0]\n",
      " [  0   2   0   0   0   0   1   3   0   0   0   0  18   1   1   0   0   0\n",
      "    0   0   0  20 167   0   0   0]\n",
      " [  0   5   0   4   3   0   0   0  23   0  16   1   0   0  12   0   1   2\n",
      "   10  12   9   0   0 144   0   3]\n",
      " [  0   0   0   2   0  18   0   0   0   0   0   0   1   1   0   0   8   0\n",
      "    6  57   1  61  17   0  79   0]\n",
      " [  3   2   0   0   9   2   0   0  30   1   3   3   0   0   0   0   1   5\n",
      "   27   2   0   0   0   3   1 121]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connectionist Bench (Sonar, Mines vs. Rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/151/data.csv\n",
      "training set size: (145, 60)\n",
      "testing set size: (63, 60)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"conn-bench-sonar\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  208\n",
      "number of features:  60\n",
      "names of the features:\n",
      " ['Attribute1' 'Attribute2' 'Attribute3' 'Attribute4' 'Attribute5'\n",
      " 'Attribute6' 'Attribute7' 'Attribute8' 'Attribute9' 'Attribute10'\n",
      " 'Attribute11' 'Attribute12' 'Attribute13' 'Attribute14' 'Attribute15'\n",
      " 'Attribute16' 'Attribute17' 'Attribute18' 'Attribute19' 'Attribute20'\n",
      " 'Attribute21' 'Attribute22' 'Attribute23' 'Attribute24' 'Attribute25'\n",
      " 'Attribute26' 'Attribute27' 'Attribute28' 'Attribute29' 'Attribute30'\n",
      " 'Attribute31' 'Attribute32' 'Attribute33' 'Attribute34' 'Attribute35'\n",
      " 'Attribute36' 'Attribute37' 'Attribute38' 'Attribute39' 'Attribute40'\n",
      " 'Attribute41' 'Attribute42' 'Attribute43' 'Attribute44' 'Attribute45'\n",
      " 'Attribute46' 'Attribute47' 'Attribute48' 'Attribute49' 'Attribute50'\n",
      " 'Attribute51' 'Attribute52' 'Attribute53' 'Attribute54' 'Attribute55'\n",
      " 'Attribute56' 'Attribute57' 'Attribute58' 'Attribute59' 'Attribute60']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [0.02   0.0371 0.0428 0.0207 0.0954 0.0986 0.1539 0.1601 0.3109 0.2111\n",
      " 0.1609 0.1582 0.2238 0.0645 0.066  0.2273 0.31   0.2999 0.5078 0.4797\n",
      " 0.5783 0.5071 0.4328 0.555  0.6711 0.6415 0.7104 0.808  0.6791 0.3857\n",
      " 0.1307 0.2604 0.5121 0.7547 0.8537 0.8507 0.6692 0.6097 0.4943 0.2744\n",
      " 0.051  0.2834 0.2825 0.4256 0.2641 0.1386 0.1051 0.1343 0.0383 0.0324\n",
      " 0.0232 0.0027 0.0065 0.0159 0.0072 0.0167 0.018  0.0084 0.009  0.0032]\n",
      "instance 0 output label:  ['R']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.78%\n",
      "F1 score: 0.78\n",
      "confusion matrix:\n",
      "[[23 12]\n",
      " [ 2 26]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Musk (Version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/75/data.csv\n",
      "training set size: (4618, 166)\n",
      "testing set size: (1980, 166)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"musk2\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  6598\n",
      "number of features:  166\n",
      "names of the features:\n",
      " ['f1' 'f2' 'f3' 'f4' 'f5' 'f6' 'f7' 'f8' 'f9' 'f10' 'f11' 'f12' 'f13'\n",
      " 'f14' 'f15' 'f16' 'f17' 'f18' 'f19' 'f20' 'f21' 'f22' 'f23' 'f24' 'f25'\n",
      " 'f26' 'f27' 'f28' 'f29' 'f30' 'f31' 'f32' 'f33' 'f34' 'f35' 'f36' 'f37'\n",
      " 'f38' 'f39' 'f40' 'f41' 'f42' 'f43' 'f44' 'f45' 'f46' 'f47' 'f48' 'f49'\n",
      " 'f50' 'f51' 'f52' 'f53' 'f54' 'f55' 'f56' 'f57' 'f58' 'f59' 'f60' 'f61'\n",
      " 'f62' 'f63' 'f64' 'f65' 'f66' 'f67' 'f68' 'f69' 'f70' 'f71' 'f72' 'f73'\n",
      " 'f74' 'f75' 'f76' 'f77' 'f78' 'f79' 'f80' 'f81' 'f82' 'f83' 'f84' 'f85'\n",
      " 'f86' 'f87' 'f88' 'f89' 'f90' 'f91' 'f92' 'f93' 'f94' 'f95' 'f96' 'f97'\n",
      " 'f98' 'f99' 'f100' 'f101' 'f102' 'f103' 'f104' 'f105' 'f106' 'f107'\n",
      " 'f108' 'f109' 'f110' 'f111' 'f112' 'f113' 'f114' 'f115' 'f116' 'f117'\n",
      " 'f118' 'f119' 'f120' 'f121' 'f122' 'f123' 'f124' 'f125' 'f126' 'f127'\n",
      " 'f128' 'f129' 'f130' 'f131' 'f132' 'f133' 'f134' 'f135' 'f136' 'f137'\n",
      " 'f138' 'f139' 'f140' 'f141' 'f142' 'f143' 'f144' 'f145' 'f146' 'f147'\n",
      " 'f148' 'f149' 'f150' 'f151' 'f152' 'f153' 'f154' 'f155' 'f156' 'f157'\n",
      " 'f158' 'f159' 'f160' 'f161' 'f162' 'f163' 'f164' 'f165' 'f166']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [  46 -108  -60  -69 -117   49   38 -161   -8    5 -323 -220 -113 -299\n",
      " -283 -307  -31 -106 -227  -42  -59  -22  -67  189   81   17  -27  -89\n",
      "  -67  105 -116  124 -106    5 -120   63 -165   40  -27   68  -44   98\n",
      "  -33 -314 -282 -335 -144  -13 -197   -2 -144  -13  -11 -131  108  -43\n",
      "   42 -151   -4    8 -102   51  -15  108 -135   59 -166   20  -20   23\n",
      "  -48  -68 -299 -256  -97 -183  -24 -271 -229 -177   -6    0 -129  112\n",
      "   15   36  -66  -54  -75  132 -188  119 -120 -312   23  -55  -53  -26\n",
      "  -71   41  -55  148 -247 -306 -308 -230 -166  -35 -205 -280 -239  -53\n",
      "  -10  -23   25   -5  163   61   59  -39   92   72  113 -107   80   25\n",
      "  -27   81 -114 -187   45 -118  -75 -182 -234  -19   12  -13  -41 -119\n",
      " -149   70   17  -20 -177 -101 -116  -14  -50   24  -81 -125 -114  -44\n",
      "  128    3 -244 -308   52   -7   39  126  156  -50 -112   96]\n",
      "instance 0 output label:  [1.]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.15%\n",
      "F1 score: 0.78\n",
      "confusion matrix:\n",
      "[[1240  433]\n",
      " [  59  248]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/17/data.csv\n",
      "training set size: (398, 30)\n",
      "testing set size: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"bc-wisc-diag\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  569\n",
      "number of features:  30\n",
      "names of the features:\n",
      " ['radius1' 'texture1' 'perimeter1' 'area1' 'smoothness1' 'compactness1'\n",
      " 'concavity1' 'concave_points1' 'symmetry1' 'fractal_dimension1' 'radius2'\n",
      " 'texture2' 'perimeter2' 'area2' 'smoothness2' 'compactness2' 'concavity2'\n",
      " 'concave_points2' 'symmetry2' 'fractal_dimension2' 'radius3' 'texture3'\n",
      " 'perimeter3' 'area3' 'smoothness3' 'compactness3' 'concavity3'\n",
      " 'concave_points3' 'symmetry3' 'fractal_dimension3']\n",
      "name of the output label:  ['Diagnosis']\n",
      "instance 0 feature vector:\n",
      " [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "instance 0 output label:  ['M']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.57%\n",
      "F1 score: 0.94\n",
      "confusion matrix:\n",
      "[[103   5]\n",
      " [  6  57]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Balance-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/12/data.csv\n",
      "training set size: (437, 4)\n",
      "testing set size: (188, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"balance-scale\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  625\n",
      "number of features:  4\n",
      "names of the features:\n",
      " ['right-distance' 'right-weight' 'left-distance' 'left-weight']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [1 1 1 1]\n",
      "instance 0 output label:  ['B']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.83%\n",
      "F1 score: 0.84\n",
      "confusion matrix:\n",
      "[[ 0 13  5]\n",
      " [ 0 80  0]\n",
      " [ 0  3 87]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contraception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/30/data.csv\n",
      "training set size: (1031, 9)\n",
      "testing set size: (442, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"contraception\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  1473\n",
      "number of features:  9\n",
      "names of the features:\n",
      " ['wife_age' 'wife_edu' 'husband_edu' 'num_children' 'wife_religion'\n",
      " 'wife_working' 'husband_occupation' 'standard_of_living_index'\n",
      " 'media_exposure']\n",
      "name of the output label:  ['contraceptive_method']\n",
      "instance 0 feature vector:\n",
      " [24  2  3  3  1  1  2  3  0]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 45.25%\n",
      "F1 score: 0.45\n",
      "confusion matrix:\n",
      "[[77 53 64]\n",
      " [13 55 33]\n",
      " [42 37 68]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fertility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/244/data.csv\n",
      "training set size: (70, 9)\n",
      "testing set size: (30, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"fertility\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  100\n",
      "number of features:  9\n",
      "names of the features:\n",
      " ['season' 'age' 'child_diseases' 'accident' 'surgical_intervention'\n",
      " 'high_fevers' 'alcohol' 'smoking' 'hrs_sitting']\n",
      "name of the output label:  ['diagnosis']\n",
      "instance 0 feature vector:\n",
      " [-0.33  0.69  0.    1.    1.    0.    0.8   0.    0.88]\n",
      "instance 0 output label:  ['N']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.33%\n",
      "F1 score: 0.92\n",
      "confusion matrix:\n",
      "[[27  0]\n",
      " [ 2  1]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Waveform (Version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/107/data.csv\n",
      "training set size: (3500, 21)\n",
      "testing set size: (1500, 21)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"waveform\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  5000\n",
      "number of features:  21\n",
      "names of the features:\n",
      " ['Attribute1' 'Attribute2' 'Attribute3' 'Attribute4' 'Attribute5'\n",
      " 'Attribute6' 'Attribute7' 'Attribute8' 'Attribute9' 'Attribute10'\n",
      " 'Attribute11' 'Attribute12' 'Attribute13' 'Attribute14' 'Attribute15'\n",
      " 'Attribute16' 'Attribute17' 'Attribute18' 'Attribute19' 'Attribute20'\n",
      " 'Attribute21']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [-1.23 -1.56 -1.75 -0.28  0.6   2.22  0.85  0.21 -0.2   0.89  1.08  4.2\n",
      "  2.89  7.75  4.59  3.15  5.12  3.32  1.2   0.24 -0.56]\n",
      "instance 0 output label:  [2]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.87%\n",
      "F1 score: 0.80\n",
      "confusion matrix:\n",
      "[[262 117 107]\n",
      " [  5 490  24]\n",
      " [  3  31 461]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/50/data.csv\n",
      "training set size: (147, 19)\n",
      "testing set size: (63, 19)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"image-segmentation\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  210\n",
      "number of features:  19\n",
      "names of the features:\n",
      " ['region-centroid-col' 'region-centroid-row' 'region-pixel-count'\n",
      " 'short-line-density-5' 'short-line-density-2' 'vedge-mean' 'vedge-sd'\n",
      " 'hedge-mean' 'hedge-sd' 'intensity-mean' 'rawred-mean' 'rawblue-mean'\n",
      " 'rawgreen-mean' 'exred-mean' 'exblue-mean' 'exgreen-mean' 'value-mean'\n",
      " 'saturation-mean' 'hue-mean']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [ 1.4000000e+02  1.2500000e+02  9.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  2.7777790e-01  6.2963010e-02  6.6666675e-01\n",
      "  3.1111118e-01  6.1851850e+00  7.3333335e+00  7.6666665e+00\n",
      "  3.5555556e+00  3.4444444e+00  4.4444447e+00 -7.8888890e+00\n",
      "  7.7777777e+00  5.4563490e-01 -1.1218182e+00]\n",
      "instance 0 output label:  ['BRICKFACE']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.67%\n",
      "F1 score: 0.65\n",
      "confusion matrix:\n",
      "[[ 3  0  0  0  0  0  6]\n",
      " [ 1  6  0  0  0  0  3]\n",
      " [ 0  1  1  0  0  0  9]\n",
      " [ 0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  9  0  0]\n",
      " [ 0  0  0  0  0  5  0]\n",
      " [ 0  0  1  0  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Blood Transfusion Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/176/data.csv\n",
      "training set size: (523, 4)\n",
      "testing set size: (225, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"blood\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  748\n",
      "number of features:  4\n",
      "names of the features:\n",
      " ['Recency' 'Frequency' 'Monetary' 'Time']\n",
      "name of the output label:  ['Donated_Blood']\n",
      "instance 0 feature vector:\n",
      " [    2    50 12500    98]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 74.67%\n",
      "F1 score: 0.68\n",
      "confusion matrix:\n",
      "[[160   5]\n",
      " [ 52   8]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SPECT Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/95/data.csv\n",
      "training set size: (186, 22)\n",
      "testing set size: (81, 22)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"spect\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  267\n",
      "number of features:  22\n",
      "names of the features:\n",
      " ['F1' 'F2' 'F3' 'F4' 'F5' 'F6' 'F7' 'F8' 'F9' 'F10' 'F11' 'F12' 'F13'\n",
      " 'F14' 'F15' 'F16' 'F17' 'F18' 'F19' 'F20' 'F21' 'F22']\n",
      "name of the output label:  ['OVERALL_DIAGNOSIS']\n",
      "instance 0 feature vector:\n",
      " [0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.56%\n",
      "F1 score: 0.59\n",
      "confusion matrix:\n",
      "[[15  0]\n",
      " [36 30]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Statlog (Landsat Satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/146/data.csv\n",
      "training set size: (4504, 36)\n",
      "testing set size: (1931, 36)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"landsat\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  6435\n",
      "number of features:  36\n",
      "names of the features:\n",
      " ['Attribute1' 'Attribute2' 'Attribute3' 'Attribute4' 'Attribute5'\n",
      " 'Attribute6' 'Attribute7' 'Attribute8' 'Attribute9' 'Attribute10'\n",
      " 'Attribute11' 'Attribute12' 'Attribute13' 'Attribute14' 'Attribute15'\n",
      " 'Attribute16' 'Attribute17' 'Attribute18' 'Attribute19' 'Attribute20'\n",
      " 'Attribute21' 'Attribute22' 'Attribute23' 'Attribute24' 'Attribute25'\n",
      " 'Attribute26' 'Attribute27' 'Attribute28' 'Attribute29' 'Attribute30'\n",
      " 'Attribute31' 'Attribute32' 'Attribute33' 'Attribute34' 'Attribute35'\n",
      " 'Attribute36']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [ 92 115 120  94  84 102 106  79  84 102 102  83 101 126 133 103  92 112\n",
      " 118  85  84 103 104  81 102 126 134 104  88 121 128 100  84 107 113  87]\n",
      "instance 0 output label:  [3]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.13%\n",
      "F1 score: 0.80\n",
      "confusion matrix:\n",
      "[[351   0  14   0  85   0]\n",
      " [  5 165   0   0  15   1]\n",
      " [  6   0 367  40   2   1]\n",
      " [  2   0  27 140   3  29]\n",
      " [ 21   1   0  11 161  25]\n",
      " [  0   0   2  94  19 344]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/110/data.csv\n",
      "training set size: (1038, 8)\n",
      "testing set size: (446, 8)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"yeast\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  1484\n",
      "number of features:  8\n",
      "names of the features:\n",
      " ['mcg' 'gvh' 'alm' 'mit' 'erl' 'pox' 'vac' 'nuc']\n",
      "name of the output label:  ['localization_site']\n",
      "instance 0 feature vector:\n",
      " [0.58 0.61 0.47 0.13 0.5  0.   0.48 0.22]\n",
      "instance 0 output label:  ['MIT']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 15.25%\n",
      "F1 score: 0.18\n",
      "confusion matrix:\n",
      "[[  0   1   7   1   0   0   2  18   0 116]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   8   0   0   0   0   0   0   2]\n",
      " [  0   0   6   9   0   0   0   0   0   0]\n",
      " [  0   0   3   4   0   0   0   0   0   4]\n",
      " [  0   0   0   0   0   1   0   4   0  46]\n",
      " [  0   0  10   3   0   0  16   2   0  43]\n",
      " [  0   0   3   1   0   0   3  26   0  93]\n",
      " [  0   0   1   0   0   0   0   0   3   0]\n",
      " [  0   0   3   2   0   0   0   0   0   5]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Monk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/70/data.csv\n",
      "training set size: (302, 6)\n",
      "testing set size: (130, 6)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"monk\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  432\n",
      "number of features:  6\n",
      "names of the features:\n",
      " ['a1' 'a2' 'a3' 'a4' 'a5' 'a6']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [1 1 1 1 1 1]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 71.54%\n",
      "F1 score: 0.72\n",
      "confusion matrix:\n",
      "[[47 14]\n",
      " [23 46]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/39/data.csv\n",
      "training set size: (235, 7)\n",
      "testing set size: (101, 7)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"ecoli\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  336\n",
      "number of features:  7\n",
      "names of the features:\n",
      " ['mcg' 'gvh' 'lip' 'chg' 'aac' 'alm1' 'alm2']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [0.49 0.29 0.48 0.5  0.56 0.24 0.35]\n",
      "instance 0 output label:  ['cp']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.27%\n",
      "F1 score: 0.67\n",
      "confusion matrix:\n",
      "[[44  1  0  0  0  0  1]\n",
      " [ 2 17  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0 11  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7]\n",
      " [ 0  0  0  0  0  1  0]\n",
      " [ 1  2  0  0  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/53/data.csv\n",
      "training set size: (105, 4)\n",
      "testing set size: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"iris\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  150\n",
      "number of features:  4\n",
      "names of the features:\n",
      " ['sepal length' 'sepal width' 'petal length' 'petal width']\n",
      "name of the output label:  ['class']\n",
      "instance 0 feature vector:\n",
      " [5.1 3.5 1.4 0.2]\n",
      "instance 0 output label:  ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.78%\n",
      "F1 score: 0.98\n",
      "confusion matrix:\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/111/data.csv\n",
      "training set size: (70, 16)\n",
      "testing set size: (31, 16)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"zoo\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  101\n",
      "number of features:  16\n",
      "names of the features:\n",
      " ['hair' 'feathers' 'eggs' 'milk' 'airborne' 'aquatic' 'predator' 'toothed'\n",
      " 'backbone' 'breathes' 'venomous' 'fins' 'legs' 'tail' 'domestic'\n",
      " 'catsize']\n",
      "name of the output label:  ['type']\n",
      "instance 0 feature vector:\n",
      " [1 0 0 1 0 0 1 1 1 1 0 0 4 0 0 1]\n",
      "instance 0 output label:  [1]\n"
     ]
    }
   ],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.32%\n",
      "F1 score: 0.91\n",
      "confusion matrix:\n",
      "[[14  0  0  1  0  0  0]\n",
      " [ 0  3  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  5  0]\n",
      " [ 0  0  1  0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
