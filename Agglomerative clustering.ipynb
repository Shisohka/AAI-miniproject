{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project: Agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Preprocessing</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before executing:\n",
    "# pip install C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm has been implemented using the library sklearn.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids =   {\n",
    "                \"parkinsons\": 174,\n",
    "                \"page-blocks\": 78,\n",
    "                \"optical\": 80,\n",
    "                \"musk2\": 75,\n",
    "                \"bc-wisc-diag\": 17,\n",
    "                \"students\": 697,\n",
    "                \"wine\": 109,\n",
    "                \"magic\": 159,\n",
    "                \"balance-scale\": 12,\n",
    "                \"glass\": 42,\n",
    "                \"zoo\": 111,\n",
    "                \"waveform\": 107,\n",
    "                \"image-segmentation\": 50,\n",
    "                \"blood\": 176,\n",
    "                \"spect\": 95,\n",
    "                \"yeast\": 110,\n",
    "                \"monk\": 70,\n",
    "                \"ecoli\": 39,\n",
    "                \"iris\": 53,\n",
    "                \"contraception\": 30,\n",
    "                \"fertility\": 244,\n",
    "                \"conn-bench-sonar\":  151,\n",
    "                \"landsat\": 146,\n",
    "                \"ionosphere\": 52,\n",
    "                \"letter\": 59,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(id):  \n",
    "    # fetch dataset \n",
    "    dataset = fetch_ucirepo(id=id) \n",
    "    \n",
    "    # data (as pandas dataframes) \n",
    "    X = dataset.data.features \n",
    "    y =dataset.data.targets \n",
    "    \n",
    "    # dictionary gthering infos about the metadata (url, abstract, ... etc.)\n",
    "    metadata_infos_dict = dataset.metadata\n",
    "    print('data url:\\n', metadata_infos_dict['data_url'])\n",
    "    \n",
    "    # variable information\n",
    "    var_infos = dataset.variables.to_numpy()\n",
    "    \n",
    "    data_vectors = X.to_numpy() #instance vectors with features\n",
    "    features_names = X.columns.to_numpy() #getting the names of each feature\n",
    "    \n",
    "    data_labels = y.to_numpy() #output labels for each instance\n",
    "    label_name = y.columns.to_numpy() # name of the output label\n",
    "    \n",
    "    return data_vectors, features_names, data_labels, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_useful_data(X, X_names, y, y_name, index = 0):\n",
    "    n_instances = len(X)\n",
    "    n_features = len(X_names)\n",
    "    \n",
    "    print(\"number of instances: \", n_instances)\n",
    "    print(\"number of features: \", n_features)\n",
    "\n",
    "    print(\"names of the features:\\n\", X_names)\n",
    "    print(\"name of the output label: \", y_name)\n",
    "\n",
    "    print(f\"instance {index} feature vector:\\n\", X[index])\n",
    "    print(f\"instance {index} output label: \", y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y, split=0.7):\n",
    "    scaler = StandardScaler()\n",
    "    try:\n",
    "        #standardization\n",
    "        X = scaler.fit_transform(X)\n",
    "    except ValueError:\n",
    "        #If non numerical data is detected, data is encoded\n",
    "        X = np.array(X, dtype=object)\n",
    "        encoder = OneHotEncoder()\n",
    "        X_encoded = encoder.fit_transform(X).toarray()\n",
    "        X = scaler.fit_transform(X_encoded)\n",
    "    \n",
    "    #data is split among training and testing sets\n",
    "    return train_test_split(X, y, train_size=split, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Accuracy, F1 and confusion matrice</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(cluster_labels, true_labels, compute_f1_cm = True):\n",
    "    unique_labels = np.unique(true_labels)\n",
    "    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    int_labels = np.array([label_to_int[label] for label in true_labels.ravel()])\n",
    "\n",
    "    #map clusters to most frequent true labels\n",
    "    cluster_to_label = {}\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        mask = cluster_labels == cluster\n",
    "        if np.any(mask):\n",
    "            most_common_label, _ = mode(int_labels[mask], axis=None)\n",
    "            cluster_to_label[cluster] = most_common_label.item()  \n",
    "        else:\n",
    "            cluster_to_label[cluster] = -1  #avoid empty clusters\n",
    "\n",
    "    #predicted labels\n",
    "    predicted_labels = np.array([cluster_to_label[cluster] for cluster in cluster_labels])\n",
    "\n",
    "    #compute accuracy\n",
    "    accuracy = np.mean(predicted_labels == int_labels)\n",
    "    \n",
    "    f1 = None\n",
    "    cm = None\n",
    "    if compute_f1_cm == True: \n",
    "        #compute F1 score\n",
    "        f1 = f1_score(int_labels, predicted_labels, average='macro')\n",
    "    \n",
    "        #compute confusion matrix\n",
    "        cm = confusion_matrix(int_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Results on 25 datasets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Predict Students' Dropout and Academic Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/697/data.csv\n",
      "training set size: (3096, 36)\n",
      "testing set size: (1328, 36)\n",
      "(4424, 1)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"students\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split=split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 49.93%\n",
      "F1 score: 0.22\n",
      "confusion matrix:\n",
      "[[   0    0 1421]\n",
      " [   0    0  794]\n",
      " [   0    0 2209]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/109/data.csv\n",
      "training set size: (124, 13)\n",
      "testing set size: (54, 13)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"wine\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 69.66%\n",
      "F1 score: 0.69\n",
      "confusion matrix:\n",
      "[[46  0 13]\n",
      " [ 2 51 18]\n",
      " [ 0 21 27]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MAGIC gamma telescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/159/data.csv\n",
      "training set size: (13314, 10)\n",
      "testing set size: (5706, 10)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"magic\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.61%\n",
      "F1 score: 0.58\n",
      "confusion matrix:\n",
      "[[10611  1721]\n",
      " [ 4629  2059]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/174/data.csv\n",
      "training set size: (136, 22)\n",
      "testing set size: (59, 22)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"parkinsons\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.38%\n",
      "F1 score: 0.43\n",
      "confusion matrix:\n",
      "[[  0  48]\n",
      " [  0 147]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Page-blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/78/data.csv\n",
      "training set size: (3831, 10)\n",
      "testing set size: (1642, 10)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"page-blocks\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.02%\n",
      "F1 score: 0.30\n",
      "confusion matrix:\n",
      "[[4911    0    2    0    0]\n",
      " [ 329    0    0    0    0]\n",
      " [  16    0   12    0    0]\n",
      " [  88    0    0    0    0]\n",
      " [ 104    0    7    0    4]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Optical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/80/data.csv\n",
      "training set size: (3933, 64)\n",
      "testing set size: (1687, 64)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"optical\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "\n",
    "num_sample = 6000\n",
    "X_train, X_test = X_train[:num_sample*2,:], X_test[:num_sample,:]\n",
    "Y_train, Y_test = Y_train[:num_sample*2], Y_test[:num_sample]\n",
    "\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.89%\n",
      "F1 score: 0.76\n",
      "confusion matrix:\n",
      "[[553   0   0   0   0   0   1   0   0   0]\n",
      " [  0 194  66   1   2   0   0   0 308   0]\n",
      " [  0   0 499   0   0   0   1   0  57   0]\n",
      " [  0   0   6 528  20   1   0   2  15   0]\n",
      " [  0  10   0   0 553   0   4   1   0   0]\n",
      " [  0   0   3  32  16 506   0   0   1   0]\n",
      " [  0   0   0   0   0   2 554   0   2   0]\n",
      " [  0   2   0   1  11   0   0 552   0   0]\n",
      " [  0   1   0   0   1   0   0   1 551   0]\n",
      " [  0   0   0 366 171   4   0  11  10   0]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/52/data.csv\n",
      "training set size: (245, 34)\n",
      "testing set size: (106, 34)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"ionosphere\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 71.79%\n",
      "F1 score: 0.71\n",
      "confusion matrix:\n",
      "[[ 92  34]\n",
      " [ 65 160]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Glass Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/42/data.csv\n",
      "training set size: (149, 9)\n",
      "testing set size: (65, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"glass\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 54.21%\n",
      "F1 score: 0.40\n",
      "confusion matrix:\n",
      "[[16 54  0  0  0  0]\n",
      " [ 4 67  0  5  0  0]\n",
      " [ 3 14  0  0  0  0]\n",
      " [ 2  0  0 11  0  0]\n",
      " [ 4  0  0  3  0  2]\n",
      " [ 3  1  0  3  0 22]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Letter Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/59/data.csv\n",
      "training set size: (14000, 16)\n",
      "testing set size: (6000, 16)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"letter\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 29.87%\n",
      "F1 score: 0.24\n",
      "confusion matrix:\n",
      "[[623   4   0   0   0   0   0   0   0   0   0   0  24   0   0   0 138   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0   0   0   0 112   0   0  43   0   0  15 296   0\n",
      "    0   0  12   0   0   0   0 152]\n",
      " [  0   0 202   0   0   0   0   0   0  51   0   0  16   0  26  71 205   0\n",
      "    0   0 165   0   0   0   0   0]\n",
      " [  3 126   0   0   0   0   0   0   0 125   0   0  12   0 286  17 209   0\n",
      "    0   0  27   0   0   0   0   0]\n",
      " [  0  38 159   0   0   0   0   0   0 102   0   0  27   0   0 145 218   0\n",
      "    0   0  21   0   0   0   0  58]\n",
      " [  0   7   0   0   0 228   0   0   0   0   0   0  12   0   1 198  82   0\n",
      "    0  76   1 170   0   0   0   0]\n",
      " [  0   2 168   0   0   0   0   0   0   0   0   0  38   0 201  35 301   0\n",
      "    0   0  28   0   0   0   0   0]\n",
      " [  0 106   0   0   0   0   0   0   0  85   0   0  47 160  63  39 152   0\n",
      "    0   0  68   0  10   0   0   4]\n",
      " [  0  16   0   0   0   0   0   0   0 233   0 203   0   0   0  34 224   0\n",
      "    0   0   1   0   0   0   0  44]\n",
      " [  0   8   0   0   0   0   0   0   0 567   0   0   1   0   7  67  83   0\n",
      "    0   0   3   0   0   0   0  11]\n",
      " [  0 105   0   0   0   0   0   0   0  89   0   0  38   0 131  30 182   0\n",
      "    0   0 103   0  24   0   0  37]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 582   5   0  13   1 153   0\n",
      "    0   0   7   0   0   0   0   0]\n",
      " [  0  51   0   0   0   0   0   0   0   0   0   0 395 163   0   0  52   0\n",
      "    0   0  90   0  41   0   0   0]\n",
      " [  0 100   0   0   0   0   0   0   0   0   0   0  82 171  77   0  37   0\n",
      "    0   0 139   2 175   0   0   0]\n",
      " [  1  15   0   0   0   0   0   0   0   0   0   0  16   0 398  52 227   0\n",
      "    0   0  44   0   0   0   0   0]\n",
      " [  0   0   0   0   0 217   0   0   0   0   0   0   1   0  17 252 114   0\n",
      "    0  43   4 155   0   0   0   0]\n",
      " [  6   5   0   0   0   0   0   0   0   0   0   0   9   0 178   0 585   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0 105   0   0   0   0   0   0   0  81   0   0  53   0 176  18 319   0\n",
      "    0   0   5   0   0   0   0   1]\n",
      " [  3  64   0   0   0   0   0   0   0  94   0   0  27   0   0  87 240   0\n",
      "    0   0  13   0   0   0   0 220]\n",
      " [  0   1   0   0   0 129   0   0   0   0   0   0  25   0  15  78  73   0\n",
      "    0 380   0   0  95   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  92   0   0  76 169  32   0  29   0\n",
      "    0   0 348   0  67   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  25   0   0  80  39   0\n",
      "    0 212   9 246 153   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  64   0   0   0  18   0\n",
      "    0   0  32   0 638   0   0   0]\n",
      " [  0 104   0   0   0   0   0   0   0  78   0   0  12   0 154  68 251   0\n",
      "    0   0  45   0  11   0   0  64]\n",
      " [  0   0   0   0   0  95   0   0   0   0   0   0  12   0   0  44 155   0\n",
      "    0 373   1   0 106   0   0   0]\n",
      " [  0  51   0   0   0   0   0   0   0  77   0   0   0   0   0 151 232   0\n",
      "    0   0   0   0   0   0   0 223]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connectionist Bench (Sonar, Mines vs. Rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/151/data.csv\n",
      "training set size: (145, 60)\n",
      "testing set size: (63, 60)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"conn-bench-sonar\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 53.37%\n",
      "F1 score: 0.35\n",
      "confusion matrix:\n",
      "[[111   0]\n",
      " [ 97   0]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Musk (Version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/75/data.csv\n",
      "training set size: (4618, 166)\n",
      "testing set size: (1980, 166)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"musk2\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 84.59%\n",
      "F1 score: 0.46\n",
      "confusion matrix:\n",
      "[[5581    0]\n",
      " [1017    0]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/17/data.csv\n",
      "training set size: (398, 30)\n",
      "testing set size: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"bc-wisc-diag\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.86%\n",
      "F1 score: 0.71\n",
      "confusion matrix:\n",
      "[[357   0]\n",
      " [126  86]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Balance-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/12/data.csv\n",
      "training set size: (437, 4)\n",
      "testing set size: (188, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"balance-scale\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 68.48%\n",
      "F1 score: 0.47\n",
      "confusion matrix:\n",
      "[[  0  15  34]\n",
      " [  0 175 113]\n",
      " [  0  35 253]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contraception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/30/data.csv\n",
      "training set size: (1031, 9)\n",
      "testing set size: (442, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"contraception\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 44.40%\n",
      "F1 score: 0.33\n",
      "confusion matrix:\n",
      "[[393   0 236]\n",
      " [168   0 165]\n",
      " [250   0 261]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fertility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/244/data.csv\n",
      "training set size: (70, 9)\n",
      "testing set size: (30, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"fertility\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.00%\n",
      "F1 score: 0.47\n",
      "confusion matrix:\n",
      "[[88  0]\n",
      " [12  0]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Waveform (Version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/107/data.csv\n",
      "training set size: (3500, 21)\n",
      "testing set size: (1500, 21)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"waveform\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 60.04%\n",
      "F1 score: 0.48\n",
      "confusion matrix:\n",
      "[[   0 1225  432]\n",
      " [   0 1344  303]\n",
      " [   0   38 1658]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/50/data.csv\n",
      "training set size: (147, 19)\n",
      "testing set size: (63, 19)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"image-segmentation\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 57.62%\n",
      "F1 score: 0.55\n",
      "confusion matrix:\n",
      "[[27  0  0  0  0  0  3]\n",
      " [ 4 13  0  0 13  0  0]\n",
      " [24  2  1  0  0  0  3]\n",
      " [ 0  0  0 16 14  0  0]\n",
      " [ 0 10  0  4 16  0  0]\n",
      " [ 0  0  0  0  0 30  0]\n",
      " [12  0  0  0  0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Blood Transfusion Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/176/data.csv\n",
      "training set size: (523, 4)\n",
      "testing set size: (225, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"blood\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.20%\n",
      "F1 score: 0.43\n",
      "confusion matrix:\n",
      "[[570   0]\n",
      " [178   0]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SPECT Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/95/data.csv\n",
      "training set size: (186, 22)\n",
      "testing set size: (81, 22)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"spect\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.40%\n",
      "F1 score: 0.44\n",
      "confusion matrix:\n",
      "[[  0  55]\n",
      " [  0 212]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Statlog (Landsat Satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/146/data.csv\n",
      "training set size: (4504, 36)\n",
      "testing set size: (1931, 36)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"landsat\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 67.15%\n",
      "F1 score: 0.52\n",
      "confusion matrix:\n",
      "[[1270    3   40    0    0  220]\n",
      " [  31  644    0    0    0   28]\n",
      " [  96    0 1262    0    0    0]\n",
      " [ 353    1  184    0    0   88]\n",
      " [ 168    7    0    0    0  532]\n",
      " [ 315    0   48    0    0 1145]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/110/data.csv\n",
      "training set size: (1038, 8)\n",
      "testing set size: (446, 8)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"yeast\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 48.58%\n",
      "F1 score: 0.36\n",
      "confusion matrix:\n",
      "[[342   4   0   7   0  36  31  42   1   0]\n",
      " [  0   5   0   0   0   0   0   0   0   0]\n",
      " [  5   0   0  27   0   1   2   0   0   0]\n",
      " [  1   0   0  41   0   0   2   0   0   0]\n",
      " [ 11   1   0  34   0   2   2   1   0   0]\n",
      " [ 64   1   0   3   0  84   6   5   0   0]\n",
      " [101   0   0  10   0   8 121   1   3   0]\n",
      " [246   3   0   4   0  29  30 117   0   0]\n",
      " [  6   0   0   2   0   0   1   0  11   0]\n",
      " [ 16   0   0   8   0   4   2   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Monk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/70/data.csv\n",
      "training set size: (302, 6)\n",
      "testing set size: (130, 6)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"monk\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.67%\n",
      "F1 score: 0.67\n",
      "confusion matrix:\n",
      "[[144  72]\n",
      " [ 72 144]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/39/data.csv\n",
      "training set size: (235, 7)\n",
      "testing set size: (101, 7)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"ecoli\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 82.74%\n",
      "F1 score: 0.58\n",
      "confusion matrix:\n",
      "[[133   0   0   0   0   0   0  10]\n",
      " [  2  47   0   0  27   0   1   0]\n",
      " [  0   0   0   0   0   0   2   0]\n",
      " [  0   0   0   0   1   0   0   1]\n",
      " [  0   3   0   0  31   0   1   0]\n",
      " [  0   0   0   0   0  17   1   2]\n",
      " [  0   0   0   0   0   0   5   0]\n",
      " [  3   0   0   0   1   3   0  45]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/53/data.csv\n",
      "training set size: (105, 4)\n",
      "testing set size: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"iris\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.33%\n",
      "F1 score: 0.89\n",
      "confusion matrix:\n",
      "[[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0 15 35]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/111/data.csv\n",
      "training set size: (70, 16)\n",
      "testing set size: (31, 16)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"zoo\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.15%\n",
      "F1 score: 0.68\n",
      "confusion matrix:\n",
      "[[37  0  0  3  1  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  3]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  6  4]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n",
    "model.fit(X_train)\n",
    "\n",
    "#labels prediction\n",
    "cluster_labels = model.fit_predict(X)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(cluster_labels, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
