{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Preprocessing</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before executing:\n",
    "# pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids =   {\n",
    "                \"parkinsons\": 174,\n",
    "                \"page-blocks\": 78,\n",
    "                \"optical\": 80,\n",
    "                \"musk2\": 75,\n",
    "                \"bc-wisc-diag\": 17,\n",
    "                \"students\": 697,\n",
    "                \"wine\": 109,\n",
    "                \"magic\": 159,\n",
    "                \"balance-scale\": 12,\n",
    "                \"glass\": 42,\n",
    "                \"zoo\": 111,\n",
    "                \"waveform\": 107,\n",
    "                \"image-segmentation\": 50,\n",
    "                \"blood\": 176,\n",
    "                \"spect\": 95,\n",
    "                \"yeast\": 110,\n",
    "                \"monk\": 70,\n",
    "                \"ecoli\": 39,\n",
    "                \"iris\": 53,\n",
    "                \"contraception\": 30,\n",
    "                \"fertility\": 244,\n",
    "                \"conn-bench-sonar\":  151,\n",
    "                \"landsat\": 146,\n",
    "                \"ionosphere\": 52,\n",
    "                \"letter\": 59,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(id):  \n",
    "    # fetch dataset \n",
    "    dataset = fetch_ucirepo(id=id) \n",
    "    \n",
    "    # data (as pandas dataframes) \n",
    "    X = dataset.data.features \n",
    "    y =dataset.data.targets \n",
    "    \n",
    "    # dictionary gthering infos about the metadata (url, abstract, ... etc.)\n",
    "    metadata_infos_dict = dataset.metadata\n",
    "    print('data url:\\n', metadata_infos_dict['data_url'])\n",
    "    \n",
    "    # variable information\n",
    "    var_infos = dataset.variables.to_numpy()\n",
    "    \n",
    "    data_vectors = X.to_numpy() #instance vectors with features\n",
    "    features_names = X.columns.to_numpy() #getting the names of each feature\n",
    "    \n",
    "    data_labels = y.to_numpy() #output labels for each instance\n",
    "    label_name = y.columns.to_numpy() # name of the output label\n",
    "    \n",
    "    return data_vectors, features_names, data_labels, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_useful_data(X, X_names, y, y_name, index = 0):\n",
    "    n_instances = len(X)\n",
    "    n_features = len(X_names)\n",
    "    \n",
    "    print(\"number of instances: \", n_instances)\n",
    "    print(\"number of features: \", n_features)\n",
    "\n",
    "    print(\"names of the features:\\n\", X_names)\n",
    "    print(\"name of the output label: \", y_name)\n",
    "\n",
    "    print(f\"instance {index} feature vector:\\n\", X[index])\n",
    "    print(f\"instance {index} output label: \", y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y, split=0.7):\n",
    "    scaler = StandardScaler()\n",
    "    try:\n",
    "        #standardization\n",
    "        X = scaler.fit_transform(X)\n",
    "    except ValueError:\n",
    "        #If non numerical data is detected, data is encoded\n",
    "        X = np.array(X, dtype=object)\n",
    "        encoder = OneHotEncoder()\n",
    "        X_encoded = encoder.fit_transform(X).toarray()\n",
    "        X = scaler.fit_transform(X_encoded)\n",
    "    \n",
    "    #data is split among training and testing sets\n",
    "    return train_test_split(X, y, train_size=split, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Gaussian Naive Bayes</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBayes:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.mean = {}\n",
    "        self.variance = {}\n",
    "        self.prior = {}\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.classes = np.unique(Y_train)\n",
    "        \n",
    "        for singular_class in self.classes:\n",
    "            X_c = X_train[Y_train.flatten() == singular_class]\n",
    "            self.mean[singular_class] = np.mean(X_c, axis=0) \n",
    "            self.variance[singular_class] = np.var(X_c, axis=0)\n",
    "            self.prior[singular_class] = X_c.shape[0] / X_train.shape[0]\n",
    "            \n",
    "    def gaussian_density(self, x, mean, var, epsilon=1e-9):\n",
    "        # Stabilize variance to avoid division by zero\n",
    "        var = var + epsilon\n",
    "        return (1 / np.sqrt(2*np.pi*var)) * np.exp(-((x-mean)**2) / (2*var))\n",
    "    \n",
    "    def predict_sample(self, X):\n",
    "        probability = []\n",
    "        for singular_class in self.classes:\n",
    "            log_likelihood = np.sum(np.log(np.maximum(self.gaussian_density(X, self.mean[singular_class], self.variance[singular_class]), 1e-6)))\n",
    "            log_prior = np.log(self.prior[singular_class])\n",
    "            probability.append(log_prior + log_likelihood)\n",
    "        \n",
    "        probability = np.array(probability)\n",
    "        return self.classes[np.argmax(probability)]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.array([self.predict_sample(x) for x in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to visualize clusters using PCA\n",
    "def visualize_clusters(X, clusters, centroids, iteration, nb_cluster, cluster_labels=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']  #define colors for clusters\n",
    "\n",
    "    #reduce the data to 2D using PCA for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2D = pca.fit_transform(X) \n",
    "\n",
    "    #if cluster assignments are provided, color by cluster membership\n",
    "    if cluster_labels is not None:\n",
    "        for i in range(nb_cluster):\n",
    "            cluster_points_2D = X_2D[cluster_labels == i]\n",
    "            plt.scatter(cluster_points_2D[:, 0], cluster_points_2D[:, 1], \n",
    "                        color=colors[i % len(colors)], label=f'Cluster {i+1}')\n",
    "    else:\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            cluster_points = np.array(cluster)\n",
    "            cluster_points_2D = pca.transform(cluster_points)  #transform current cluster into 2D\n",
    "            plt.scatter(cluster_points_2D[:, 0], cluster_points_2D[:, 1], \n",
    "                        color=colors[i % len(colors)], label=f'Cluster {i+1}')\n",
    "\n",
    "    #plot centroids in 2D space\n",
    "    centroids_2D = pca.transform(centroids)  #transform centroids into 2D\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                color='black', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(f\"clusters and centroids - Iteration {iteration}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Accuracy, F1 and confusion matrice</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    \n",
    "    return accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Results on 25 datasets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Predict Students' Dropout and Academic Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/697/data.csv\n",
      "training set size: (3096, 36)\n",
      "testing set size: (1328, 36)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"students\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split=split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 69.28%\n",
      "F1 score: 0.68\n",
      "confusion matrix:\n",
      "[[309  55  77]\n",
      " [ 44  68 133]\n",
      " [ 38  61 543]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/109/data.csv\n",
      "training set size: (124, 13)\n",
      "testing set size: (54, 13)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"wine\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100.00%\n",
      "F1 score: 1.00\n",
      "confusion matrix:\n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MAGIC gamma telescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/159/data.csv\n",
      "training set size: (13314, 10)\n",
      "testing set size: (5706, 10)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"magic\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 72.75%\n",
      "F1 score: 0.70\n",
      "confusion matrix:\n",
      "[[3410  295]\n",
      " [1260  741]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/174/data.csv\n",
      "training set size: (136, 22)\n",
      "testing set size: (59, 22)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"parkinsons\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.27%\n",
      "F1 score: 0.78\n",
      "confusion matrix:\n",
      "[[12  3]\n",
      " [11 33]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Page-blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/78/data.csv\n",
      "training set size: (3831, 10)\n",
      "testing set size: (1642, 10)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"page-blocks\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.27%\n",
      "F1 score: 0.90\n",
      "confusion matrix:\n",
      "[[1311    7    8  118   22]\n",
      " [  24   79    1    2    0]\n",
      " [   2    0    7    0    1]\n",
      " [   0    2    0   28    1]\n",
      " [  12    0    5    4    8]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Optical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/80/data.csv\n",
      "training set size: (3933, 64)\n",
      "testing set size: (1687, 64)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"optical\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "\n",
    "num_sample = 6000\n",
    "X_train, X_test = X_train[:num_sample*2,:], X_test[:num_sample,:]\n",
    "Y_train, Y_test = Y_train[:num_sample*2], Y_test[:num_sample]\n",
    "\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 61.94%\n",
      "F1 score: 0.60\n",
      "confusion matrix:\n",
      "[[170   0   0   0   0   0   0   0   0   0]\n",
      " [  0 116   0   0   0   0  14   0  38   5]\n",
      " [  2  12  66   0   0   0   0   0  74   0]\n",
      " [  7   0   0  50   0   0   0   8 104   4]\n",
      " [ 21  24   0   0  43   0  37  49   6   3]\n",
      " [ 21   1   0   0   0  46   1   8  74   2]\n",
      " [  1   1   0   0   0   0 166   0   0   0]\n",
      " [  0   3   0   0   0   0   0 180   3   0]\n",
      " [  3   2   0   0   0   0   0   1 147   0]\n",
      " [ 38   6   0   0   0   0   2  21  46  61]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/52/data.csv\n",
      "training set size: (245, 34)\n",
      "testing set size: (106, 34)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"ionosphere\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.68%\n",
      "F1 score: 0.88\n",
      "confusion matrix:\n",
      "[[28 11]\n",
      " [ 1 66]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Glass Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/42/data.csv\n",
      "training set size: (149, 9)\n",
      "testing set size: (65, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"glass\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 21.54%\n",
      "F1 score: 0.21\n",
      "confusion matrix:\n",
      "[[ 0  1 18  0  0  0]\n",
      " [ 1  3 15  0  4  0]\n",
      " [ 1  0  3  0  0  0]\n",
      " [ 0  3  0  1  2  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  1  5  4]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Letter Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/59/data.csv\n",
      "training set size: (14000, 16)\n",
      "testing set size: (6000, 16)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"letter\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 64.30%\n",
      "F1 score: 0.64\n",
      "confusion matrix:\n",
      "[[213   0   0   0   0   0   0   1   0   0   1   0   6   1   0   0   1   1\n",
      "    7   0   0   0   0   0   1   0]\n",
      " [  0 155   0   6   0   0   2   5  20   0   5   0   4   0   2   0   4  16\n",
      "    5   0   0   0   4   1   0   0]\n",
      " [  0   0 144   0   6   1  16   1   0   0  11   0   2   0   6   0   4   0\n",
      "    5   2   2   1   0   0   0   0]\n",
      " [  2  13   0 193   0   0   0   5   3   5   5   0   3   0   3   1   0  11\n",
      "    4   0   0   0   1   1   0   0]\n",
      " [  0   5   1   0  84   0  43   0  22   0   9   0   0   0   0   0  12   0\n",
      "   19   4   0   0   0  33   2   4]\n",
      " [  0   9   0   9   0 152   9   1   1   0   0   0   0   4   0   9   5   1\n",
      "    4   4   0   0   2   0   1   0]\n",
      " [  5   6  50   1   1   0 127   0   4   0   2   0   4   0   2   0  12   4\n",
      "    4   0   0   0   6   2   0   0]\n",
      " [  1   6   0  19   0   0   3  67   4   0   9   0   5   2  35   0   1  20\n",
      "    1   0   8   0   0  32   5   0]\n",
      " [  0   4   0  22   2   0   0   0 164   7   0   2   0   0   0   1   3   0\n",
      "   13   1   0   0   0   1   0   1]\n",
      " [  2   6   0  10   0   5   0   0   6 161   1   0   0   0   3   6   3   6\n",
      "   17   0   0   0   0   2   0   0]\n",
      " [  1   4   3   4  19   0   7   0   2   0  89   0   7   0   0   0   0  24\n",
      "    0   1   3   0   1  23   0   0]\n",
      " [  1   7   0   0   5   0   4   0   0  15   9 176   1   0   0   0   9   2\n",
      "    1   0   0   0   0   0   1   0]\n",
      " [  5   2   0   0   0   0   1   2   0   0   6   0 226   0   2   0   0   0\n",
      "    0   0   0   0   8   0   0   0]\n",
      " [  0   3   0   5   0   1   0  20   0   0   5   0   8 155   5   1   2   7\n",
      "    2   0   2   8   7   0   0   0]\n",
      " [  2   4   0   5   0   0   8   2  11   0   4   0   5   2 154   1   3  10\n",
      "    0   0   0   0   7   0   0   0]\n",
      " [  0   1   0   2   0  30  11   1   0   0   0   0   1   4   1 181   0   0\n",
      "    1   1   0   0  13   0   1   0]\n",
      " [  2   5   0   2   0   0   5   1   9   0   0   0   6   0  57   0 132   7\n",
      "   23   0   0   1   1   0   1   1]\n",
      " [  0  22   0  23   0   0   1   5   3   7   5   0  11   0   0   0   0 152\n",
      "    0   0   0   0   4   1   0   0]\n",
      " [ 15  33   0   3   5   2   2   2  19   0   2   0   1   0   0   1   4   3\n",
      "   84   7   1   0   0  29   0  22]\n",
      " [  0   1   1   1   1  13   4   0   0   0  13   0   1   0   0   0   0   1\n",
      "    2 160   1   2   0  10  18   3]\n",
      " [  0   0   4   1   0   2   3   9   0   0  11   0  22   6  14   0   1   0\n",
      "    0   0 184   0   4   0   0   0]\n",
      " [  0   3   0   0   0   2   2   3   0   0   1   0   2   0   0   4   0   1\n",
      "    0   0   0 194  18   0   7   0]\n",
      " [  0   2   0   0   0   0   1   3   0   0   0   0  18   1   1   0   0   0\n",
      "    0   0   0  20 167   0   0   0]\n",
      " [  0   5   0   4   3   0   0   0  23   0  16   1   0   0  12   0   1   2\n",
      "   10  12   9   0   0 144   0   3]\n",
      " [  0   0   0   2   0  18   0   0   0   0   0   0   1   1   0   0   8   0\n",
      "    6  57   1  61  17   0  79   0]\n",
      " [  3   2   0   0   9   2   0   0  30   1   3   3   0   0   0   0   1   5\n",
      "   27   2   0   0   0   3   1 121]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connectionist Bench (Sonar, Mines vs. Rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/151/data.csv\n",
      "training set size: (145, 60)\n",
      "testing set size: (63, 60)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"conn-bench-sonar\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.78%\n",
      "F1 score: 0.78\n",
      "confusion matrix:\n",
      "[[23 12]\n",
      " [ 2 26]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Musk (Version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/75/data.csv\n",
      "training set size: (4618, 166)\n",
      "testing set size: (1980, 166)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"musk2\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.15%\n",
      "F1 score: 0.78\n",
      "confusion matrix:\n",
      "[[1240  433]\n",
      " [  59  248]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/17/data.csv\n",
      "training set size: (398, 30)\n",
      "testing set size: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"bc-wisc-diag\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.57%\n",
      "F1 score: 0.94\n",
      "confusion matrix:\n",
      "[[103   5]\n",
      " [  6  57]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Balance-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/12/data.csv\n",
      "training set size: (437, 4)\n",
      "testing set size: (188, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"balance-scale\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.83%\n",
      "F1 score: 0.84\n",
      "confusion matrix:\n",
      "[[ 0 13  5]\n",
      " [ 0 80  0]\n",
      " [ 0  3 87]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contraception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/30/data.csv\n",
      "training set size: (1031, 9)\n",
      "testing set size: (442, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"contraception\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 45.25%\n",
      "F1 score: 0.45\n",
      "confusion matrix:\n",
      "[[77 53 64]\n",
      " [13 55 33]\n",
      " [42 37 68]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fertility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/244/data.csv\n",
      "training set size: (70, 9)\n",
      "testing set size: (30, 9)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"fertility\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.33%\n",
      "F1 score: 0.92\n",
      "confusion matrix:\n",
      "[[27  0]\n",
      " [ 2  1]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Waveform (Version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/107/data.csv\n",
      "training set size: (3500, 21)\n",
      "testing set size: (1500, 21)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"waveform\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.87%\n",
      "F1 score: 0.80\n",
      "confusion matrix:\n",
      "[[262 117 107]\n",
      " [  5 490  24]\n",
      " [  3  31 461]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/50/data.csv\n",
      "training set size: (147, 19)\n",
      "testing set size: (63, 19)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"image-segmentation\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.67%\n",
      "F1 score: 0.65\n",
      "confusion matrix:\n",
      "[[ 3  0  0  0  0  0  6]\n",
      " [ 1  6  0  0  0  0  3]\n",
      " [ 0  1  1  0  0  0  9]\n",
      " [ 0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  9  0  0]\n",
      " [ 0  0  0  0  0  5  0]\n",
      " [ 0  0  1  0  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Blood Transfusion Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/176/data.csv\n",
      "training set size: (523, 4)\n",
      "testing set size: (225, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"blood\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 74.67%\n",
      "F1 score: 0.68\n",
      "confusion matrix:\n",
      "[[160   5]\n",
      " [ 52   8]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SPECT Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/95/data.csv\n",
      "training set size: (186, 22)\n",
      "testing set size: (81, 22)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"spect\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.56%\n",
      "F1 score: 0.59\n",
      "confusion matrix:\n",
      "[[15  0]\n",
      " [36 30]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Statlog (Landsat Satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/146/data.csv\n",
      "training set size: (4504, 36)\n",
      "testing set size: (1931, 36)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"landsat\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.13%\n",
      "F1 score: 0.80\n",
      "confusion matrix:\n",
      "[[351   0  14   0  85   0]\n",
      " [  5 165   0   0  15   1]\n",
      " [  6   0 367  40   2   1]\n",
      " [  2   0  27 140   3  29]\n",
      " [ 21   1   0  11 161  25]\n",
      " [  0   0   2  94  19 344]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/110/data.csv\n",
      "training set size: (1038, 8)\n",
      "testing set size: (446, 8)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"yeast\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 15.25%\n",
      "F1 score: 0.18\n",
      "confusion matrix:\n",
      "[[  0   1   7   1   0   0   2  18   0 116]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   8   0   0   0   0   0   0   2]\n",
      " [  0   0   6   9   0   0   0   0   0   0]\n",
      " [  0   0   3   4   0   0   0   0   0   4]\n",
      " [  0   0   0   0   0   1   0   4   0  46]\n",
      " [  0   0  10   3   0   0  16   2   0  43]\n",
      " [  0   0   3   1   0   0   3  26   0  93]\n",
      " [  0   0   1   0   0   0   0   0   3   0]\n",
      " [  0   0   3   2   0   0   0   0   0   5]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Monk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/70/data.csv\n",
      "training set size: (302, 6)\n",
      "testing set size: (130, 6)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"monk\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 71.54%\n",
      "F1 score: 0.72\n",
      "confusion matrix:\n",
      "[[47 14]\n",
      " [23 46]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/39/data.csv\n",
      "training set size: (235, 7)\n",
      "testing set size: (101, 7)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"ecoli\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.27%\n",
      "F1 score: 0.67\n",
      "confusion matrix:\n",
      "[[44  1  0  0  0  0  1]\n",
      " [ 2 17  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0 11  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7]\n",
      " [ 0  0  0  0  0  1  0]\n",
      " [ 1  2  0  0  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/53/data.csv\n",
      "training set size: (105, 4)\n",
      "testing set size: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"iris\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.78%\n",
      "F1 score: 0.98\n",
      "confusion matrix:\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data url:\n",
      " https://archive.ics.uci.edu/static/public/111/data.csv\n",
      "training set size: (70, 16)\n",
      "testing set size: (31, 16)\n"
     ]
    }
   ],
   "source": [
    "X, X_names, y, y_name = load_dataset(id = dataset_ids[\"zoo\"])\n",
    "split_size = 0.7\n",
    "X_train, X_test, Y_train, Y_test = preprocessing(X, y, split_size)\n",
    "print(f'training set size: {X_train.shape}')\n",
    "print(f'testing set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_useful_data(X, X_names, y, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.32%\n",
      "F1 score: 0.91\n",
      "confusion matrix:\n",
      "[[14  0  0  1  0  0  0]\n",
      " [ 0  3  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  5  0]\n",
      " [ 0  0  1  0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = GaussianBayes()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#labels prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy, f1, cm = calculate_metrics(Y_test, Y_pred)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
