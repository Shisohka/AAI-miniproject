{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-NN on the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 datasets\n",
    "dataset_ids =   {\n",
    "                \"parkinsons\": 174,\n",
    "                \"page-blocks\": 78,\n",
    "                \"optical\": 80,\n",
    "                \"musk2\": 75,\n",
    "                \"bc-wisc-diag\": 17,\n",
    "                \"students\": 697,\n",
    "                \"wine\": 109,\n",
    "                \"magic\": 159,\n",
    "                \"balance-scale\": 12,\n",
    "                \"glass\": 42,\n",
    "                \"zoo\": 111,\n",
    "                \"waveform\": 107,\n",
    "                \"image-segmentation\": 50,\n",
    "                \"blood\": 176,\n",
    "                \"spect\": 95,\n",
    "                \"yeast\": 110,\n",
    "                \"monk\": 70,\n",
    "                \"ecoli\": 39,\n",
    "                \"iris\": 53,\n",
    "                \"contraception\": 30,\n",
    "                \"fertility\": 244,\n",
    "                \"conn-bench-sonar\":  151,\n",
    "                \"landsat\": 146,\n",
    "                \"ionosphere\": 52,\n",
    "                \"letter\": 59,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(id, show_info = False):  \n",
    "    # fetch dataset \n",
    "    dataset = fetch_ucirepo(id=id) \n",
    "    \n",
    "    # data (as pandas dataframes) \n",
    "    X = dataset.data.features \n",
    "    y =dataset.data.targets \n",
    "    \n",
    "    # dictionary gthering infos about the metadata (url, abstract, ... etc.)\n",
    "    metadata_infos_dict = dataset.metadata\n",
    "    \n",
    "    if show_info:\n",
    "        print('data url:\\n', metadata_infos_dict['data_url'])\n",
    "    \n",
    "    # variable information\n",
    "    var_infos = dataset.variables.to_numpy()\n",
    "    \n",
    "    data_vectors = X.to_numpy() #instance vectors with features\n",
    "    features_names = X.columns.to_numpy() #getting the names of each feature\n",
    "    \n",
    "    data_labels = y.to_numpy() #output labels for each instance\n",
    "    label_name = y.columns.to_numpy() # name of the output label\n",
    "    \n",
    "    return data_vectors, features_names, data_labels, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_datasets(dataset_ids):\n",
    "    \n",
    "    datasets = {}\n",
    "    for i, dataset_name in enumerate(dataset_ids.keys()):\n",
    "        \n",
    "        scaler_minmax = MinMaxScaler()\n",
    "        \n",
    "        X, X_names, y, y_name = load_dataset(id = dataset_ids[dataset_name])\n",
    "        datasets[dataset_name] = {}\n",
    "        datasets[dataset_name][\"X\"] = scaler_minmax.fit_transform(X)\n",
    "        datasets[dataset_name][\"X_names\"] = X_names\n",
    "        datasets[dataset_name][\"y\"] = y\n",
    "        datasets[dataset_name][\"y_name\"] = y_name\n",
    "        \n",
    "        print(f\"'{dataset_name}' dataset loaded ({i+1}/{len(dataset_ids.keys())})\")\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'parkinsons' dataset loaded (1/25)\n",
      "'page-blocks' dataset loaded (2/25)\n",
      "'optical' dataset loaded (3/25)\n",
      "'musk2' dataset loaded (4/25)\n",
      "'bc-wisc-diag' dataset loaded (5/25)\n",
      "'students' dataset loaded (6/25)\n",
      "'wine' dataset loaded (7/25)\n",
      "'magic' dataset loaded (8/25)\n",
      "'balance-scale' dataset loaded (9/25)\n",
      "'glass' dataset loaded (10/25)\n",
      "'zoo' dataset loaded (11/25)\n",
      "'waveform' dataset loaded (12/25)\n",
      "'image-segmentation' dataset loaded (13/25)\n",
      "'blood' dataset loaded (14/25)\n",
      "'spect' dataset loaded (15/25)\n",
      "'yeast' dataset loaded (16/25)\n",
      "'monk' dataset loaded (17/25)\n",
      "'ecoli' dataset loaded (18/25)\n",
      "'iris' dataset loaded (19/25)\n",
      "'contraception' dataset loaded (20/25)\n",
      "'fertility' dataset loaded (21/25)\n",
      "'conn-bench-sonar' dataset loaded (22/25)\n",
      "'landsat' dataset loaded (23/25)\n",
      "'ionosphere' dataset loaded (24/25)\n",
      "'letter' dataset loaded (25/25)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_all_datasets(dataset_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of k-NN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kNN(Xtr, ytr, Xtst, k: int = 1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    if len(ytr.shape) > 1:\n",
    "        ytr = ytr[:, 0]\n",
    "    knn.fit(Xtr, ytr)\n",
    "    ypred = knn.predict(Xtst)\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(Xtr, ytr, n_fold, num_sample = None, seed: int = 42):\n",
    "    if n_fold >= 2:\n",
    "        if num_sample is None:\n",
    "            num_sample = len(Xtr)\n",
    "            \n",
    "        Tr_set = Xtr[:num_sample]\n",
    "        Ltr_set = ytr[:num_sample]\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        avg_len = num_sample//n_fold\n",
    "        remainder = num_sample%n_fold\n",
    "        \n",
    "        extra_list = np.zeros(n_fold)\n",
    "        extra_folders = np.random.choice(range(n_fold), size=remainder, replace=False)\n",
    "        extra_list[extra_folders] = 1\n",
    "        \n",
    "        train_folders = []\n",
    "        train_labels = []\n",
    "        start_ind = 0\n",
    "        end_ind = None\n",
    "        for i in range(n_fold):\n",
    "            folder_size = avg_len + int(extra_list[i])\n",
    "            end_ind = start_ind + folder_size\n",
    "            folder = Tr_set[start_ind:end_ind]\n",
    "            labels = Ltr_set[start_ind:end_ind]\n",
    "\n",
    "            train_folders.append(folder)\n",
    "            train_labels.append(labels)\n",
    "                \n",
    "            start_ind = end_ind\n",
    "            \n",
    "        return train_folders, train_labels\n",
    "    else:\n",
    "        print(\"n_fold must be atleast 2\")\n",
    "\n",
    "def get_mean_accuracy(Tr_set_list, Ltr_set_list, k):\n",
    "    n_fold = len(Tr_set_list)\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    for i in range(n_fold):\n",
    "        Val_set = Tr_set_list[i]\n",
    "        Lval_set = Ltr_set_list[i]\n",
    "        \n",
    "        indexes = list(range(n_fold)).pop(i)\n",
    "        Tr_set = np.vstack(Tr_set_list[indexes])\n",
    "        Ltr_set = np.vstack(Ltr_set_list[indexes])[:,0]\n",
    "        \n",
    "        Labels_predicted = predict_kNN(Tr_set, Ltr_set, Val_set, k)\n",
    "        accuracy = accuracy_score(Labels_predicted, Lval_set)\n",
    "        \n",
    "        total_accuracy += accuracy\n",
    "        \n",
    "    mean_accuracy = total_accuracy/n_fold\n",
    "    \n",
    "    return mean_accuracy\n",
    "        \n",
    "def get_best_k(Tr_set_list, Ltr_set_list, k_list):\n",
    "    max_accuracy = 0\n",
    "    best_k_list = []\n",
    "    for k in k_list:\n",
    "        mean_accuracy = get_mean_accuracy(Tr_set_list, Ltr_set_list, k)\n",
    "               \n",
    "        if mean_accuracy > max_accuracy:\n",
    "            best_k_list = []\n",
    "            best_k_list.append(k)\n",
    "            max_accuracy = mean_accuracy\n",
    "        elif mean_accuracy == max_accuracy:\n",
    "            best_k_list.append(k)\n",
    "        \n",
    "    return best_k_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best k value for each dataset and getting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(datasets, dataset_name):\n",
    "    X = datasets[dataset_name][\"X\"]\n",
    "    y = datasets[dataset_name][\"y\"]\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "def split_train_test(X, y, train_ratio = 0.9, seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n_instances = len(X)\n",
    "    ntr = round(n_instances*train_ratio)\n",
    "    \n",
    "    indices = np.arange(n_instances)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    Xtr = X[indices[:ntr]]\n",
    "    ytr = y[indices[:ntr]]\n",
    "    \n",
    "    Xtst = X[indices[ntr:]]\n",
    "    ytst = y[indices[ntr:]]\n",
    "    \n",
    "    return Xtr, ytr, Xtst, ytst   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1/25: parkinsons\n",
      "Best k value: 1, accuracy: 94.73684210526315%\n",
      "\n",
      "Dataset 2/25: page-blocks\n",
      "Best k value: 1, accuracy: 97.44058500914076%\n",
      "\n",
      "Dataset 3/25: optical\n",
      "Best k value: 1, accuracy: 99.11032028469751%\n",
      "\n",
      "Dataset 4/25: musk2\n",
      "Best k value: 1, accuracy: 95.45454545454545%\n",
      "\n",
      "Dataset 5/25: bc-wisc-diag\n",
      "Best k value: 1, accuracy: 96.49122807017544%\n",
      "\n",
      "Dataset 6/25: students\n",
      "Best k value: 1, accuracy: 64.02714932126696%\n",
      "\n",
      "Dataset 7/25: wine\n",
      "Best k value: 1, accuracy: 88.88888888888889%\n",
      "\n",
      "Dataset 8/25: magic\n",
      "Best k value: 1, accuracy: 80.91482649842271%\n",
      "\n",
      "Dataset 9/25: balance-scale\n",
      "Best k value: 1, accuracy: 76.19047619047619%\n",
      "\n",
      "Dataset 10/25: glass\n",
      "Best k value: 1, accuracy: 52.38095238095239%\n",
      "\n",
      "Dataset 11/25: zoo\n",
      "Best k value: 1, accuracy: 100.0%\n",
      "\n",
      "Dataset 12/25: waveform\n",
      "Best k value: 1, accuracy: 78.8%\n",
      "\n",
      "Dataset 13/25: image-segmentation\n",
      "Best k value: 1, accuracy: 85.71428571428571%\n",
      "\n",
      "Dataset 14/25: blood\n",
      "Best k value: 1, accuracy: 70.66666666666667%\n",
      "\n",
      "Dataset 15/25: spect\n",
      "Best k value: 1, accuracy: 81.48148148148148%\n",
      "\n",
      "Dataset 16/25: yeast\n",
      "Best k value: 1, accuracy: 50.0%\n",
      "\n",
      "Dataset 17/25: monk\n",
      "Best k value: 1, accuracy: 62.7906976744186%\n",
      "\n",
      "Dataset 18/25: ecoli\n",
      "Best k value: 1, accuracy: 82.35294117647058%\n",
      "\n",
      "Dataset 19/25: iris\n",
      "Best k value: 1, accuracy: 93.33333333333333%\n",
      "\n",
      "Dataset 20/25: contraception\n",
      "Best k value: 1, accuracy: 45.57823129251701%\n",
      "\n",
      "Dataset 21/25: fertility\n",
      "Best k value: 1, accuracy: 80.0%\n",
      "\n",
      "Dataset 22/25: conn-bench-sonar\n",
      "Best k value: 1, accuracy: 95.23809523809523%\n",
      "\n",
      "Dataset 23/25: landsat\n",
      "Best k value: 1, accuracy: 91.601866251944%\n",
      "\n",
      "Dataset 24/25: ionosphere\n",
      "Best k value: 1, accuracy: 97.14285714285714%\n",
      "\n",
      "Dataset 25/25: letter\n",
      "Best k value: 1, accuracy: 96.15%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def apply_knn(datasets, dataset_name, n_fold, k_list):\n",
    "    \n",
    "    #Getting the data vectors\n",
    "    X, y = get_x_y(datasets, dataset_name)\n",
    "    Xtr, ytr, Xtst, ytst = split_train_test(X, y) #splitting train and test parts\n",
    "    \n",
    "    #Searching for the best k with cross-validation method\n",
    "    Tr_set_list, Ltr_set_list = data_split(Xtr, ytr, n_fold)\n",
    "    best_k_list = get_best_k(Tr_set_list, Ltr_set_list, k_list)\n",
    "    best_k = best_k_list[-1]\n",
    "    \n",
    "    ypred = predict_kNN(Xtr, ytr, Xtst, k = best_k)\n",
    "\n",
    "    #computing the accuracy\n",
    "    accuracy = accuracy_score(ytst, ypred)\n",
    "    \n",
    "    return best_k, accuracy\n",
    "    \n",
    "\n",
    "def apply_knn_on_all(datasets, n_fold = 3, k_list = range(1,10)):\n",
    "    \n",
    "    for i, dataset_name in enumerate(datasets.keys()):\n",
    "        print(f\"Dataset {i+1}/{len(datasets.keys())}: {dataset_name}\")\n",
    "        \n",
    "        best_k, accuracy = apply_knn(datasets, dataset_name, n_fold, k_list)\n",
    "        \n",
    "        print(f\"Best k value: {best_k}, accuracy: {100*accuracy}%\") \n",
    "        print('')\n",
    "        \n",
    "apply_knn_on_all(datasets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
